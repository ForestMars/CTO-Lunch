- og c&b
    
    Are we in an AI bubble? OpenAI’s own leadership has hinted as much. On August 18, Sam Altman admitted there “could be” an AI bubble, while analysts noted that AI has become too big to fail: the so-called "Mag 7" tech stocks now account for 35% of the S&P 500. Any hit to these AI-centric giants could rattle the broader market. Meanwhile, OpenAI insiders have sold over $10 billion in stock at a $500 billion valuation, freeing up shares for additional funding even as executives livestream their models’ superiority, positioning GPT as the default over competitors like Claude.
    
    The GPT-5 launch crystallized the tension between hype and reality. Promised as a "Manhattan Project of AI" or the "second coming of Ultron," the rollout delivered a desk lamp instead of fireworks. The event suffered from overhyped expectations, routing failures, service transparency issues, and backlash against the deactivation of prior "sycophantic" versions. Users quickly demanded the return of GPT-4o, forced by GPT-5’s colder persona. And the launch video? A funereal, tonally disconnected affair featuring egregious chart crimes.
    
    Yet amid the drama, product lead Kevin Weil quietly delivered a major triumph: GPT-5 saved customers millions while reducing OpenAI’s supply-side costs. In any rational universe, this would be a career milestone. In ours, it was buried under nine minutes of corporate backslapping, overshadowed by Altman’s malapropisms and the launch’s spectacle. Additional wins, like the announcement of **Stargate Norway**, OpenAI’s first new global data center, barely made the headlines.
    
    In an interview following the release of GPT-5, Altman, musing about data centers on the moon, suggested the solution to covering Earth with compute would be to “simply build a Dyson sphere around the solar system.” This was not hyperbole. It revealed a stunning confusion between Type I and Type II civilizations on the Kardashev scale, a fundamental misunderstanding of what a Dyson sphere is, and a broader detachment from physical reality. When a CEO publicly espouses this level of absurdity, it signals not technical ambition but a personality-driven narrative designed to justify massive cash burn.
    
    So are we already in a Dyson Bubble: self-contained sphere of hype and absurd promises, designed to shield the product from a market increasingly demanding substance over spectacle. It’s a bubble in valuation, a bubble in executive credibility, and a bubble in belief itself. Without even throwing hallucinations into the mix. I’m old enough to remember the 2023 release scare (when OpenAI claimed their latest model was “too dangerous to ship”) which already hinted at a reliance on *belief in the mission* over clear monetization.
