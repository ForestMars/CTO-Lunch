## It’s Conference Szn

**The final quarter of the year kicked off** not just the Fall Conference Season, but a definitively leveraged resurgence in the U.S. tech sector, inaugurated by the White House Tech Dinner on September 4; planned as the first official event in the newly renovated Rose Garden and which served as a high-stakes, a trillion-dollar spectacle focused on capital allocation for Tech and AI investment, withtotal domestic investment pledges in AI infrastructure and manufacturing announced surpassing a somewhat staggering $1.4 Trillion by 2028. (That’s literally over 2 billion a month from now til then.)

Elon and Jensen both had other things to attend to, which was fine; there's only so much energy you can fit in the room, leaving Zuckerberg to grab the choice seat on the President's right. (Poor Gates had to pass notes through Melania on his left.) Fine by me since I didn't even get an invitation. Which was also fine by me since there was also only one CTO in attendance at this “tech” dinner. (I’ll let you guess if it was Palantir or Anduril.) 

The White House dinner set the stage; the  investment, the optics, the political theate, all signaling the scale of *what’s coming.* But the real work is happening elsewhere. Engineering leaders are already grappling with the operational and organizational challenges of the AI-first era, to turn these abstract mandates into executable plans. The season’s two gatherings where this work was most visible and consequential were ELC Annual in San Francisco at Fort Mason, so all the cool kids met up later at [The Interval](https://longnow.org/interval/)) and CTO Craft Con in Berlin. 
The core questions being debugged were remarkably consistent across continents: How do we actually scale our AI initiatives? What does non-performative governance look like? And why does integrating AI into our workflows so often make our most experienced engineers *slower?* (And also often, grumpier.) 

### ELC Annual: Refactor Your Playbook

**ELC Annual conference in San Francisco is the single highest-value summit** for engineering leadership because it has zero interest in the low-signal clutter of traditional trade shows for more of an executive work session intended to address the mission-critical issues keeping CTOs awake at night. It’s highly collaborative with Roundtable Discussions and meticulous curated 1:1 meetings to ensure every connection is a strategic consultation. This highly focused model has cemented the event's reputation for delivering actionable wisdom directly from leaders in the trenches, making it a mandatory professional investment for the top eng leaders cohort. Somewhat surprisingly there didn’t seem to be many CTO Lunch list members in attendance, though it’s also a newish event, having only gotten off the ground a few years ago as an “unconference.” 

This year's theme, "AI Rewrote Leadership. Refactor Your Playbook," acknowledged what's happening across our industry: the AI experimental phase is over, but most organizations still have no idea how to execute at scale. The shift is as profound as the move to cloud computing, except it's happening faster and the architectural implications go even deeper. For the past 18 months, CTOs have been running pilots, experimenting with agents, and watching our teams use ChatGPT and Claude in ways that violate approximately every security policy ever written. Executive teams have been patient, remarkably patient by C-suite standards, waiting for productivity gains to materialize beyond anecdotal, and not always true, "my team loves it" reports. Now the bill is coming due. Past due, if you ask your CFO, who wants ROI numbers. Boards want strategic frameworks. And everyone is learning together that bolting AI onto existing architectures is like trying to run Kubernetes on a LAMP stack: technically possible (no, it really is) but catastrophically wrong. (Obvi.) 

The (un)conference crystallized around three pillars of "AI Native Leadership" that you can think of more or less as diagnostic criteria for whether your engineering org is about to get lapped. First, architectural simplicity in the age of agentic complexity (code for: your microservices architecture is about to look adorably quaint.); Second, scaling innovation through internal competition, matryoshka-style, where governance is the actual bottleneck (not because anyone cares about ethics theater, but because it's the real constraint preventing deployment); and Third, resource-conscious leadership, which sounds like the same old "do more with less" mantra until you realize that AI-driven teams require organizational and cultural reconfiguration, sophisticated measurement frameworks, and is effectively blurring the lines between engineering, product, and business. Maybe we’re finally understanding that scaling isn’t about increasing headcount? 

It sounds obvious out of context but what’s truly fundamental is the shift in developer experience. The cloud-native era was about CI/CD automation and platform adoption, getting developers to use the tools we built. Similarly, the agentic AI era is about AI-integrated DevEx except we haven’t yet built the tools we want them to be using. This is where platform engineering teams need to "own the loop" by integrating seamless AI assistance that minimizes cognitive load while ensuring high-quality outputs. Data architecture has transformed from relational databases and data lakes into vector databases, hybrid search, and RAG loops where contextual knowledge becomes a critical, performance-gated infrastructure layer. That’s a lot to unpack before we even start pushing it out to not just our teams, but cross-functionally across the whole org. 

AI can easily exacerbates the already tight bottlenecks in such collaboration, particularly in the design-to-code handoff where design & engineering collide in Storybook or whatever reconciliation loop you’re using to curtail the chaos. Instead of accelerating workflow, AI assistance often slows down experienced team while helping junior developers catch up, two steps forward, three steps back. This pattern keeps showing up in studies, leading to odd conversations about team composition and the need for senior engineering expertise in an AI-assisted world. Meanwhile, the infrastructure requirements aren't subtle: vector databases have moved from experimental to mandatory, RAG architectures are table stakes (esp. for avoiding hallucinated compliance violations) and the orchestration layer for managing autonomous agents requires rethinking the entire SDLC.  The cloud-native era's primary risks were supply chain integrity and dreaded configuration drift; the agentic era's risks remind us that we palliated those concerns more than we actually solved them, requiring Agentic DevSecOps (a popular buzzword at ELC) methodologies rebuilt almost from scratch. 

ELC 2025 marked the point where AI strategy finally got operational. Every conversation was about execution: which architectures hold up under load, which governance models survive contact with reality, what teams that are actually shipping know that you don’t. The signal was clear: this isn’t theory anymore. The next phase belongs to leaders who can translate architectural clarity into organizational momentum, because the experimentation window is closing fast. 

- vers1
    
    If ELC Annual was about the tactical and architectural translation of AI strategy, CTO Craft Con in Berlin was the essential counterpoint, focusing squarely on the *organizational and cultural re-engineering* required to survive the transition. Held at the Spielfeld Digital Hub from September 23–24, the core narrative was not about code or infrastructure—it was that technology is cultural.
    
    The European cohort of engineering leadership is grappling with the same AI mandates, but with an intense overlay of "Permacrisis"—a market defined by geopolitical instability, persistent economic uncertainty, and a pervasive lack of faith in organizational leadership. In this environment, the CTO’s job transforms from merely managing technical execution to managing extreme complexity at the collision point of technological disruption and organizational volatility.
    
    The consensus was clear: the primary bottleneck to AI scale-up is no longer technical complexity; it’s organizational maturity. Startups, though they face their own existential challenges, have a clear advantage here—they lack the entrenched legacy inertia that makes operational refactoring feel like performing open-heart surgery on a running engine. For everyone else, the old saw that "the problem lies in organizational resistance" is less a complaint and more a diagnostic indicator that the leadership structure is failing to adapt.
    
    This is why a new CTO archetype is emerging—one who is not just technical but who must also become the Chief Cultural Officer. Citing the work of thinkers like Don Ihde, the conference posited that the ability to genuinely scale AI is inherently linked to cultivating a high-trust culture of "Challenger Safety." This is the psychological safety required for engineers to challenge flawed AI outputs, push back on unethical applications, and debug the *system* rather than just the code.
    
    The most provocative discussions centered on how to combat leadership burnout and the alarming statistic that 41% of engineering leaders are actively considering leaving their roles. The solution presented was a technical re-engagement: in an environment where trust in co-leadership is low, the CTO’s mandate is to drive Platform Driven Operational Efficiency. This is the non-performative mandate where platform engineering is used to build internal product surfaces that reduce cognitive load, enforce necessary governance (i.e., making "the right thing the easiest thing"), and deliver verifiable efficiency gains.
    
    The ultimate takeaway from Berlin was a necessary shift in perspective: the problem of scale is not solved by increasing headcount, it's solved by re-engaging the technical hands of the CTO. In a permacrisis environment, the mandate is to leverage technical systems—specifically Platform Engineering and AI tooling—to restore organizational certainty and build the cultural fortitude required to navigate the next decade. The build-founder revolution is, in many ways, being driven by the lack of faith in existing corporate leadership; technical leaders are now forced to *build* the company culture they can trust.
    
- vers2
    
    **If ELC Annual was about the tactical and architectural translation of AI strategy**, **CTO Craft Con** in Berlin was the essential counterpoint, focusing squarely on the *organizational and cultural re-engineering* required to survive the transition. Held at the Spielfeld Digital Hub (September 23–24) CTO Craft is where European tech leadership cohort goes to admit what's actually broken. Unlike the Valley's performance optimism, Berlin's engineering culture has always trafficked in a certain, dare I say, German pessimism and this year’s iteration distilled this sensibility into a two-day diagnostic of what happens when you try to run an AI-first org in what’s being called the "permacrisis" of economic volatility, geopolitical chaos, and the persistent sense that whatever stability you thought you had just became a liability. 
    
    The central thesis wasn't subtle: technology is cultural, and CTOs who don't understand this are managing the wrong variables. My last COO used to joke that I was also the Chief Cultural Officer, and there's a deeper reason for that than my perceived erudition. As Don Ihde pointed out in his writings on technological mediation, technology doesn't just solve problems, it reshapes the organizational context in which those problems exist. The GenAI acceleration has made this uncomfortably explicit. You can't bolt AI onto a low-trust culture and expect anything but expensive theater. You can't mandate platform engineering adoption without first cultivating what the conference called "Challenger Safety," the organizational capacity to question architectural decisions without triggering defensive bureaucracy or political retaliation.
    
    The burnout data finally got concrete: 41% of engineering leaders are actively considering leaving their roles, and the reasons track directly to the structural contradictions the conference spent both days unpacking. Leadership wants transformative AI deployment but won't fund the technical debt remediation required to make it viable. Boards want platform-driven operational efficiency but still measure success through headcount growth. Everyone wants innovation, but the organizational maturity required to sustain it, verifiable processes, genuine psychological safety, architectural clarity, remains aspirational at best. Startups have an odd advantage here: they lack legacy inertia to unwind, so they can mature faster, sort of like how people used to look older at the same age. But that only works if they're intentional about building the right cultural scaffolding from the start, which most aren't. (ca. OpenAI’s DevDay announcement they are basically Roundup for startups.) 
    
    Technical re-engagement as a mandate emerged as the conference's sharpest diagnostic. The archetype of the CTO as pure people manager, the one who "graduated" from hands-on work years ago, is failing catastrophically in the agentic era. You cannot architect for AI scale-up from 30,000 feet. You cannot evaluate RAG pipelines, vector database performance, or agent orchestration frameworks through executive summaries. The complexity is too high, the pace too fast, and the gap between what vendors promise and what actually ships is too wide. Permacrisis has become a driver of what some are calling the builder-founder revolution: technical leaders who can still ship are suddenly worth exponentially more than those who can only delegate, and the market is repricing accordingly.
    
    Platform engineering became the conference's organizing principle for making this concrete. Not platform engineering as aspirational excellence, which is an organizational smell that you're optimizing the wrong layer, but platform engineering as operational reality. Can your platform team actually reduce cognitive load for developers integrating AI tooling? Have you built the feedback loops that let you measure whether your abstractions help or hurt? (cf. DX, following) Are you owning the loop, or just adding more process overhead to an already fragmented developer experience? The questions were sharper than the answers, which was the point. Like the inflection from experimentation to execution highlighted at ELC, this isn't solved yet, but at least the European cohort is asking the right questions rather than presuming the answers are obvious.
    
    The permacrisis framing cuts deeper than economic uncertainty. It's fundamentally about the erosion of trust—in co-leadership, in architectural decisions, in the assumption that what worked last quarter will work next quarter. High-trust organizational culture isn't a nice-to-have anymore; it's the only environment where technical leaders can make the kind of rapid, high-stakes decisions that AI deployment requires. ~~Berlin made it clear that scaling still isn't about increasing headcount, which would certainly be one less longstanding headache. It's about building systems and cultures that can absorb complexity without collapsing into coordination overhead or political paralysis. We're finally learning that lesson, though whether we're learning it fast enough is the question keeping everyone awake.~~
    
    ~~It's about building systems and cultures that can absorb complexity without collapsing into coordination overhead or political paralysis. We're finally learning that lesson, though whether we're learning it fast enough is the question keeping everyone awake.~~
    
- CTO Craft Con Berlin is where the European tech leadership cohort goes to admit what's actually broken. Unlike the Valley's performance optimism, Berlin's engineering culture has always trafficked in a certain practical pessimism—the kind that asks "but will it actually work?" before the demo even loads. The conference, held September 23-24 at Spielfeld Digital Hub, distilled this sensibility into a two-day diagnostic of what happens when you try to run an AI-first org in what they're calling "permacrisis": economic volatility, geopolitical chaos, and the persistent sense that whatever stability you thought you had just became a liability.
    
    The central thesis wasn't subtle: technology is cultural, and CTOs who don't understand this are managing the wrong variables. My last COO used to joke that I was also the Chief Cultural Officer, and there's a deeper reason for that than my perceived erudition. As Don Ihde pointed out in his work on technological mediation, technology doesn't just solve problems—it reshapes the organizational context in which those problems exist. The GenAI acceleration has made this uncomfortably explicit. You can't bolt AI onto a low-trust culture and expect anything but expensive theater. You can't mandate platform engineering adoption without first cultivating what the conference called "Challenger Safety"—the organizational capacity to question architectural decisions without triggering defensive bureaucracy or political retaliation.
    
    The burnout data finally got concrete: 41% of engineering leaders are actively considering leaving their roles, and the reasons track directly to the structural contradictions the conference spent two days unpacking. Leadership wants transformative AI deployment but won't fund the technical debt remediation required to make it viable. Boards want platform-driven operational efficiency but measure success through headcount growth. Everyone wants innovation, but the organizational maturity required to sustain it—verifiable processes, genuine psychological safety, architectural clarity—remains aspirational at best. Startups have an odd advantage here: they lack legacy inertia to unwind, so they can mature faster, like how people used to look older at the same age. But that only works if they're intentional about building the right cultural scaffolding from the start, which most aren't.
    
    The technical re-engagement mandate emerged as the conference's sharpest diagnostic. The archetype of the CTO as pure people manager, the one who "graduated" from hands-on work years ago, is failing catastrophically in the agentic era. You cannot architect for AI scale-up from 30,000 feet. You cannot evaluate RAG pipelines, vector database performance, or agent orchestration frameworks through executive summaries. The complexity is too high, the pace too fast, and the gap between what vendors promise and what actually ships is too wide. Permacrisis has become a driver of what some are calling the build-founder revolution: technical leaders who can still ship are suddenly worth exponentially more than those who can only delegate, and the market is repricing accordingly.
    
    Platform engineering became the conference's organizing principle for making this concrete. Not platform engineering as aspirational excellence—that's an organizational smell, a sign you're optimizing the wrong layer—but platform engineering as operational reality. Can your platform team actually reduce cognitive load for developers integrating AI tooling? Have you built the feedback loops that let you measure whether your abstractions help or hurt? Are you owning the loop, or just adding more process overhead to an already fragmented developer experience? The questions were sharper than the answers, which was the point. This isn't solved yet, but at least the European cohort is asking the right questions instead of pretending the answers are obvious.
    
    The permacrisis framing cuts deeper than economic uncertainty. It's fundamentally about the erosion of trust—in co-leadership, in architectural decisions, in the assumption that what worked last quarter will work next quarter. High-trust organizational culture isn't a nice-to-have anymore; it's the only environment where technical leaders can make the kind of rapid, high-stakes decisions that AI deployment requires. Berlin made it clear that scaling still isn't about increasing headcount, which would certainly be one less longstanding headache. It's about building systems and cultures that can absorb complexity without collapsing into coordination overhead or political paralysis. We're finally learning that lesson, though whether we're learning it fast enough is the question keeping everyone awake.
    
- vers4
    
    **If ELC Annual was about translating AI strategy into architectural reality,** CTO Craft Con in Berlin was the necessary counterpoint: how do you actually execute when your organization is fundamentally unprepared for what you're trying to build? Held September 23-24 at Spielfeld Digital Hub, the conference's core narrative wasn't about code or infrastructure. It was that technology is cultural, and CTOs who haven't internalized this are optimizing the wrong layer.
    
    The European engineering leadership cohort is facing the same AI mandates as their Valley counterparts, but with an overlay of what the conference termed "permacrisis"—geopolitical instability, economic uncertainty, and a pervasive erosion of faith in organizational leadership. In this environment, the CTO role transforms from managing technical execution to managing extreme complexity at the collision point of technological disruption and organizational volatility. My last COO used to joke that I was also the Chief Cultural Officer. There's a deeper reason for that than my perceived erudition, and Berlin made it explicit: you cannot scale AI on a low-trust culture. You cannot mandate platform adoption without first building what they called "Challenger Safety"—the organizational capacity to question architectural decisions, push back on flawed AI outputs, and debug the system rather than just the code.
    
    The consensus was striking: the primary bottleneck to AI scale-up is no longer technical complexity. It's organizational maturity. Startups have an odd advantage here—they lack the legacy inertia that makes refactoring feel like performing open-heart surgery on a running engine. They can mature faster, like how people used to look older at the same age, but only if they're intentional about building the right cultural scaffolding from the start. For everyone else, the old complaint that "the problem lies in organizational resistance" has become a diagnostic indicator that the leadership structure itself is failing to adapt.
    
    The burnout data finally got concrete: 41% of engineering leaders are actively considering leaving their roles. The reasons track directly to structural contradictions. Leadership wants transformative AI deployment but won't fund the technical debt remediation required to make it viable. Boards want platform-driven operational efficiency but measure success through headcount growth. The solution presented wasn't subtle: technical re-engagement. The archetype of the CTO as pure people manager, the one who "graduated" from hands-on work years ago, is failing catastrophically. You cannot architect for AI scale-up from 30,000 feet. You cannot evaluate RAG pipelines or agent orchestration frameworks through executive summaries. Permacrisis has become a driver of what some are calling the build-founder revolution: technical leaders who can still ship are suddenly worth exponentially more than those who can only delegate.
    
    Platform engineering became the organizing principle for making this operational. Not platform engineering as aspirational excellence—that's an organizational smell—but as the mechanism for reducing cognitive load, enforcing governance by making the right thing the easiest thing, and delivering verifiable efficiency gains. The conference pushed hard on Don Ihde's insight that technology doesn't just solve problems—it reshapes the organizational context in which those problems exist. GenAI has made this uncomfortably explicit. The challenge isn't deploying the models; it's building the cultural fortitude and technical systems that let your organization absorb the resulting complexity without collapsing into coordination overhead or political paralysis.
    
    Berlin's ultimate message was a necessary correction: scaling isn't about increasing headcount. It's about CTOs re-engaging technically to build the systems and cultures that can navigate permacrisis without burning out the people doing the actual work. The build-founder revolution is being driven by a lack of faith in existing corporate leadership, and technical leaders are responding by building the companies they can actually trust. The experimentation window is closing. The next phase belongs to leaders who can execute on both layers—architectural clarity and cultural transformation—simultaneously.
    

### TL;DR

The mandate from ELC is stark: refactor architecture for agentic systems immediately, allocate protected time for cultural reskilling (the Duolingo approach got namechecked repeatedly for ensuring actual competency rather than superficial AI fluency), and move governance away from shallow activity metrics toward outcome-focused frameworks like the AI Impact Framework or QuADS that link AI-amplified throughput to strategic business objectives and justify the capital investment to the board. Incremental integration is insufficient. Success requires architectural foundations, talent reskilling, team restructuring, and outcome-based governance. The organizations treating AI as incremental tooling are falling behind those treating it as architectural transformation. The question isn't whether to adopt AI. It's whether your current foundations can support what's coming. ELC made clear: most can't.

### CTO Craft Berlin

 **CTO Craft Con: Berlin** (September 23–24) is a highly focused event for Chief Technology Officers and senior tech leaders, designed to be smaller, smarter, and centered around four pillars: **Leadership, Technology, Culture, and Wellbeing**. Its agenda tackles practical organizational evolution, covering topics from building lean, high-performing teams to defining new engineering capabilities to meet shifting business models, with a heavy emphasis on mitigating the *burnout* and cultural strain of constant change.
TL;dr
TL;dr
TL;dr
TL;dr
