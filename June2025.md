This month‚Äôs CTO Lunch is Thursday, June 12. Sign up (below) for location.

Tech continues to propagate at a relentless clip, and this month brought (more) shifts that affect the core of what we do as CTOs. OpenAI made big bets, Anthropic leveled up, and Google had its best I/O to date. Data stacks are under pressure, with AI‚Äôs scale demands forcing serious architectural rethinking. And the regulatory and security background is moving the furniture around in real time. (Is it just me or does it feel like every metaphor sounds like AI these days?) Meanwhile, NYC‚Äôs tech scene is quietly outshining Silicon Valley. I would say something about ‚Äúdropping the glove‚Äù but again, that would probably sound too AI

For CTOs, just keeping pace isn‚Äôt enough anymore, if it ever was. The real challenge is reading all these shifts as they happen and knowing which ones actually change your game plan. It‚Äôs no longer about what‚Äôs new; it‚Äôs about what‚Äôs real. (And what scales. And who‚Äôs paying attention.) So if you‚Äôre paying attention, LFG:

NYC Tech Economy Booming
New York‚Äôs tech landscape is no longer just Wall Street meets venture capital; it‚Äôs a full-throttle ecosystem, where DoubleClick‚Äôs legacy as digital ad pioneer still echoes, but today's story is all about AI startups, fintech disruptors, and big data center plays. NYC is rebooting itself as a gritty innovation hub that‚Äôs less Silicon Valley shine and more Brooklyn spline (albeit with a Manhattan portfolio.)

Technical Specs
Economic Data: Tech employs 400,000+ in NYC (2025 estimate), with AI firms adding 15% growth year-over-year. Data center capacity expanded 20% since 2024.

Key Players: Startups like DoubleClick successors (e.g., AppNexus) and fintechs (e.g., Plaid) lead, backed by $5B in venture funding Q1 2025.

Infrastructure: 5G rollout covers 85% of Manhattan, supporting low-latency AI apps. Canvas tools enable seamless remote collaboration.

Industry Impact
NYC‚Äôs tech boom is a goldmine for CTOs; talent here is plentiful (with an increasing number of SF transplants) and the infrastructure to support serious AI workloads mere nanoseconds away from Wall Street. But real estate costs and regulatory hurdles are real. Lean into our local talent for AI projects, but keep an eye on compliance; this isn‚Äôt a free-for-all like the dot-com days. (Unless you're day running meme coins, obviously.)

The AI ‚ÄòRloveution‚Äô
Context and Background
This was the month AI stopped pretending it knew what it wanted to be. OpenAI lit almost $10B on fire tryna buy a strategy (with Sama/Ive's "io" landing like an overdesigned shrug) then ghost-launched plodding o3-pro with barely a whisper. Anthropic responded with tactical maneuvering and real upgrades, including the top benchmarked coding model, but buried them under ‚ÄúAI Safety Level 3‚Äù theatrics. (Literally the same week Eliezer Yudkowsky signed a female fan‚Äôs breasts.) Apple shipped an on-device model no one can use yet. All of which served to invite the question: is this really a revolution or just AI playing musical chairs while investors gets restless?

Is Open AI Treading Water?
OpenAI used to speak in grand terms about AGI and Superintelligence and nuclear launch codes and national security. Now they‚Äôre buying VS Code forks and sparring with Gary Marcus on X. They announced they are acquiring Windsurf (ARR: $40M in 2024) for an astounding $3 billion (that‚Äôs a 75x multiple, which is eye-popping even by tech sector standards.) Windsurf is a money factory, sure, (expected revenue of $300M in 2025, which is 10x their 2024 income) but at that multiple, it‚Äôs unclear whether it actually moves the needle for OpenAI, or even whether it‚Äôs moving in the right direction. And no one should confuse this mini shopping spree with Zuckerberg‚Äôs acquisitions of WhatsApp and Instagram, which were clearly about scaling user bases and ecosystem consolidation, generally speaking the kind of thing you want to be spending the big money on. In contrast, it's unclear what exactly OpenAI is buying in Windsurf (besides time.)

Anthropic Goes to Defcon 3
Seemingly in response to Open AI‚Äôs purchase of Windsurf, Anthropic pulled Claude from that app (though you can still use it with bring-your-own-key.) The big announcement tho was of course the release of their 4th generation models, Claude Opus 4 (72.5% SWE-bench, 43.2% Terminal-bench) and Sonnet 4 (72.7% SWE-bench) which being the high scorer led to it being heralded as the best coding model. But it‚Äôs ok, Gemini, we still love you anyway for your long context window (MRCR: 94.5% at 128k).

Anthropic also introduced their (first) bug bounty program, aimed at testing the safety of their systems and activated ‚ÄúAI Safety Level 3‚Äù protections, so apparently SOTA AI is currently at DefCon 3.

Apple: We‚Äôre Not Cooked Yet
"The software just didn't converge in the way we thought it would."

Not to be outdone, Apple introduced a new Foundation Models framework for iOS that gives developers direct access to a ~3B parameter on-device language model, with deep Swift integration for those still pretending they enjoy writing Swift (I kid, I kid.)
They also introduced ‚Äúvibe coding‚Äù in XCode, following the wake of controversy over what vibe coding really means, as the rush of books to take advantage of this hot topic changed the definition of vibe coding to suit their own needs (much to Andrej Karpathy‚Äôs chagrin.) That‚Äôs the thing about vibes, tho.

Meanwhile, Apple execs spent a week defending their AI strategy after quietly axing several major Siri upgrades that were trumpeted at WWDC; features that, as it turns out, ‚Äúdidn‚Äôt converge in the way we expected.‚Äù Which is Cupertino-speak for: we overpromised and underdelivered, sorry, bro. See you on the earnings call.

Almost seeming to justify their misses (based on the timing anyway) Apple published a new paper co-authored by their senior AI director Samy Bengio that generated quite a lot of buzz around the idea that models don‚Äôt actually think. Or to be more precise: all models have an upper bound on problem difficulty. Response was swift and brutal with several parody papers noting that since humans also have an upper bound, perhaps the problem is that humans don‚Äôt actually reason themselves (which was actually a trenchant critique of what most people took to be the authors‚Äô claim) as well as directly addressing the question Can Language Models Reason? (A: No, because that would be scary.)

Technical Specs
OpenAI‚Äôs planned $3B Windsurf acquisition ($300M ARR 2025, 10x 2024 growth) and $6.5B io partnership ($9.5B equity) dilutes non-profit voting control over the for-profit entity by 3.2% (9.5/300); Softbank‚Äôs $40B infusion (on a $300B pre-money valuation) drops to $30B if OpenAI fails to fully transition to for-profit by Dec 31, 2025.

io: Hardware lacks specs bc there‚Äôs no actual product announcement, just a treacle video that wrapped itself in nostalgia with no technical details. But whatever it is requires 55 new engineers apparently.

Oh, and o3-pro scores 63.8% SWE-bench if you care.

Anthropic: Claude Opus 4 (72.5% SWE-bench, 43.2% Terminal-bench), Sonnet 4 (72.7% SWE-bench) set new records for any models.

Google: Gemini 2.5 Pro: 1M token context window (2M planned), 64K max output tokens, 63.8% SWE-Bench Verified, excels in deep reasoning for coding and complex tasks. Gemini 2.5 Flash: 1M token context window, 24K max thinking budget, ~50% SWE-Bench Verified, optimized for low latency with 700+ t/s Vertex throughput, prioritizing speed over reasoning depth.

Apple Foundation Models: ~3B parameter on-device model, Swift-integrated, for iOS apps. Siri features shelved due to ‚Äúquality convergence‚Äù issues.

DeepSeek: Their May 28th update (R1-0528) to DeepSeek R1 puts performance on par with OpenAI o1, but open-sourced and with fully open reasoning tokens. It's 671B parameters in size, with 37B active in an inference pass, and available from 7 providers through openrouter.

Industry Impact
OpenAI‚Äôs acquisitions seem more tactical than strategic (unless the strategy is to reduce control of their profit entity by the non-profit, which they must do by EOY or lose $10B); it‚Äôs also unclear if they are really aware of how bad the io video flopped, or in denial about that. Anthropic‚Äôs generative coding lead and safety push have big appeal for enterprise, though the Defcon 3 thing feels a bit theatrical. Meanwhile Google is quietly leveraging their established position to AI all the things with a focus on real-time multimodal capabilities (Astra, AI Mode) and creative tools (Flow, Veo 3) that differentiates it from Anthropic‚Äôs enterprise and safety focus and OpenAI‚Äôs general-purpose agentic approach. Apple‚Äôs framework is a developer win, but Siri‚Äôs flop dents their credibility yet again.

CTOs: ignore the bluster and focus on tools with proven ROI. Altman‚Äôs got none of Jobs‚Äô taste; we could be seeing a $30B train wreck in slow motion. Read The Illusion of Thinking paper, don‚Äôt just read about it.

AI Code Generation Surge
Context and Background
So how is AI code generation going? GitHub Copilot made a remarkabe $500M ARR in 2024, launched their new agent, while OpenAI (who lost $5 BILLION in 2024) added their Codex agent to ChatGPT; meanwhile, Google‚Äôs agent Jules went into beta. Tech giants rushed to brag their stats, with Microsoft, Google and Meta all claiming AI is now generating 20-30% of the code they‚Äôre shipping. So apparently we‚Äôre back to counting loc. Sorry to anyone who thought we laid that ghost to rest.

Klarna, who loudly proclaimed to be replacing their workforce with AI became a political football in all this, with competing PR firms placing stories both that their much heralded use of AI to replace employees was backfiring spectacularly and also that their revenue per employee had skyrocketed. Sorry to keep you in suspense which is actually true. Klarna also ended their SalesForce partnership, which is ironic (in the Alanisian sense) because if there‚Äôs another CEO who‚Äôs been as vocally bullish as Klarna‚Äôs about AI reducing headcount, it‚Äôs Marc Benioff. (With Nadella and Krishna getting place and show respectively.) And then there was the Buider.ai code gen scandal (not to be confused with the completely innocent builder.io!) revealing that the AI you replace your employees with might just be different employees in a far off place, and not actually AI at all.

But mechanical turk startup scams aside , how good is all this code slop? Firecrawl, the model-first, prompt-driven data transformation pipeline to ‚Äúturn websites into LLM-ready data" have been looking to hire not 1 but 3 AI coding agents to add to their team (up to $1M TC) but haven‚Äôt found a single one worth hiring yet, out of 50 ‚Äòapplicants‚Äô so far. (But as they say on the other side of the GPU custody battle, ‚Äúwe‚Äôre so early.‚Äù)

Technical Specs
Copilot: $500M ARR, powers 40% of GitHub‚Äôs coding workflows with Codex-derived models. GitHub Copilot now supports fully autonomous async agents for feature building, bug fixes, and refactoring.

Codex: agent powered by codex-1, a version of their o3 AI reasoning model optimized for software engineering tasks, with <1s latency. Merged 345,000 PRs on Github in its first 35 days. (Read that number again.)

Jules: Google‚Äôs agent, beta with 65% accuracy on WebDev Arena tasks.

Builder.ai: Blew through nearly $450M before anyone realized it was humans writing their ‚ÄúAI‚Äù code and they were caught round-tripping (circular billing) with partner companies complicit in their scam.

Firecrawl: Tests 50 AI agents; none meet the threshold for precision.

Sourcegraph Amp: Seeming to care quite a lot about precision in version numbering, released version 0.0.1749312731 of their VS extension AmpCode coding assistant. They are also producing a software bill of materials of all the open source software used in Amp (coincidentally, software bill of goods was one of the Biden tech policies Trump reversed this month, see below.)

entelligence released their Github app for code review and an official GitHub Action (ai-pr-reviewer) which you configure by adding a .github/workflows/ai-pr-reviewer.yml file; which configures their bot (e.g., @Entelligence.AI) to comment on your pull requests using environment variables eg. GITHUB_TOKEN and OPENAI_API_KEY.

OpenCode is a Go-based CLI application (TUI) that brings AI assistance to your terminal.

Xcode: ‚Äúvibe coding‚Äù suggests context-aware code snippets, but raises questions about how context aware Apple is. (and has no actual benchmarks claimed.)

Industry Impact
Copilot‚Äôs revenue proves AI coding‚Äôs traction, but 20-30% claims raise more questions than they answer; CTOs know quality‚Äôs the real test, obvi. Jules and Codex seem solid for prototyping but vibe coding‚Äôs still just a buzzword even if Apple wants to capitalize it (or just capitalize on it.) Firecrawl‚Äôs experience more than hints at overhyped agents. CTOs, plan for real productivity gains and don‚Äôt trust the hype. AI applying for jobs? We‚Äôre closer than you think, but not there yet.

Data Engineering
Context and Background
The Postgres ecosystem is growing and consolidating at the same time. Databricks bought Neon for $1B to fold serverless Postgres into its AI stack, then arch-competitor Snowflake (who are betting big on Python and Iceberg) snapped up the last* remaining Enterprise grade Postgres service Crunchy Data for $250M (just a few weeks later); with Neon off the table, Crunchy was the only serious move left if Snowflake wanted to match Databricks on transaction credibility.

At the same time, companies like Xata and FoundationDB are reimagining Postgres for modern, AI-driven developer workflows. Following the release of their Agent v0.2.0 in April, Xata relaunched as a full *Postgres at scale* platform, a fully pg-compatible service with instant copy‚Äëon‚Äëwrite branching, built-in PII anonymization, and storage/compute separation using NVMe/TCP; it‚Äôs fully vanilla Postgres on top of distributed storage. Meanwhile there‚Äôs a new pg extension aimed at FoundationDB (pgfdb) to use it as storage engine for a fully distributed (master-master!) Postgres. It‚Äôs experimental, not officially supported (yet) but is one to watch.

The broader data stack is fragmenting under the pressure of these AI-native demands. dbt is no longer just ‚ÄúT after EL,‚Äù pivoting hard into semantic layers with Mesh. Airbyte is shipping observability agents; DuckDB went server-mode; MotherDuck raised $52M to push it cloud-native. Dagster and Prefect are locked in a tight feature race. (Airflow 3.0, we hardly knew you.) And a new crop of startups (Piper, Decile, others) are building LLM-native ETL from scratch. The old extract-transform-load model is being torn apart and reassembled for a world where compute is cheap, data is messy, and latency matters less than alignment.

Technical Specs
Snowflake + Crunchy: Snowflake acquires Crunchy Data (~$30M ARR, ~$250M deal), gaining Crunchy Bridge + full pgAdmin ecosystem; phased integration into Snowflake‚Äôs native Postgres connectors and Iceberg stack by or begins Q3.

*EnterpriseDB: (EDB) is technically the last remaining independent enterprise grade postgres offering. No shade.

FoundationDB: pgfdb is an xperimental heap access method to use FoundationDB‚Äôs MVCC key-value store as a Postgres storage (engine) layer; fully stateless compute, globally consistent, master-master capable. Latency benchmarks show sub-10ms reads at scale; no WAL, no VACUUM. Wow.

Xata: Postgres on CloudNativePG with dynamic branching via NVMe/TCP and built-in PII masking. Xata Agent v0.2.0 enables persistent AI chat for workload diagnostics. Targets use cases across multi-tenant SaaS and developer self-serve.

Supabase: Implements end-to-end type inference across client, edge, and database using declarative schemas + TypeScript. Added vector search backed by pgvector 0.6, integrated with RLS and foreign data wrappers.

Prisma MCP: Modern control plane integrates Windsurf for hot-reload schema updates; enables programmatic GraphQL + SQL-type sync from one source-of-truth model. Optimized for full-stack TypeScript workflows.

dbt Mesh: Treats semantic layers as versioned, modular assets. Git-based governance, decoupled from warehouse execution. Supports federated modeling across domains, with DAG visualizations and schema diff tooling.

Airbyte: Adds OpenLineage metadata layer, improving impact analysis and observability; supports 350+ connectors with native CDC for MySQL, Postgres, and Mongo.

DuckDB: Now supports persistent multiclient sessions via DuckDB Server. Opens path to OLAP-in-place; supports Parquet, Arrow, and Hive metastores with zero-copy reads.

Dagster: Asset-aware orchestration with hybrid DAG execution across local and cloud runners. Refreshed UI integrates partitioned materialization state and backfill tooling. Python-native, declarative I/O.

Piper: LLM-native ETL layer combining prompt chaining with auto-synthesized SQL sketches. Experimental now, but shows potential in non-tabular extraction and schema suggestion.

Industry Impact
The modern data stack is splintering under AI pressure with Postgres poised to come into its fully distributed era. What used to be vertical is now branching. Xata and pgfdb mark the rise of stateless Postgres backends optimized for AI-native workloads. Supabase and Prisma are solidifying a new app-to-db type pipeline (which Typescript‚Äôs rewrite in Go extends to LLMs, btw) while DuckDB‚Äôs move to server mode sets it on a crash course with warehouse incumbents.

For CTOs, now is the time to reassess Postgres workloads through the lens of distributed, stateless backends (like pgfdb, Aurora, and Xata) especially for AI-driven applications where latency tolerance and scalability matter. Embracing semantic modeling early is critical, as tools like dbt Mesh signal Git-native governance becoming the new baseline. Observability 1.0 is no longer sufficient; comprehensive metadata lineage and asset tracking are essential for navigating the complexity of increasingly fragmented pipelines. Meanwhile, LLM-native ETL solutions such as Piper and Decile remain experimental but offer CTOs valuable insight into the future of data workflows. Given ongoing consolidation, it‚Äôs vital to rigorously test integrations and design architectures that allow for component swap-ability to avoid lock-in and hidden complexity.

But ETL isn‚Äôt dead, it‚Äôs just grown a few extra letters. Call it ETLLLMMCP, stitched together with prompt chains, agents, and metadata sync.

SDLC Evolution
Context and Background
Java just turned 30 though with a bit of a shrug, while JavaScript got Explicit Resource Management. TypeScript‚Äôs rewrite in Go (which Anders Hejlsberg cites LLM speed as one of the main drivers of) now has a TS compiler preview available via npm and front-end development is leaning harder into AI-fueled micro frameworks. It‚Äôs more of a quiet revolution (much like Java‚Äôs early days, some 30 years ago.)

Technical Specs
TypeScript Native: Compiler rewitten in Go for 2x parsing throughput, enabling stateless builds and schema lifting; AST and symbol table synchronization with LLM prompt tokens via shared protobuf schema ensures 1-to-1 mapping between TS types and generative context in a bidirectional pipeline where type safety enforces prompt integrity and model completions inherit structural guarantees.

JavaScript ERM: Adds using declarations for resource cleanup, compatible with Node.js 22.

Enzyme: React testing library updated, supports hooks and context with 95% coverage.

Prism AI: Session replay analysis, integrates with Mixpanel; accuracy untested.

Industry Impact
TypeScript‚Äôs Go pivot is such a win: faster builds and type synergy with LLMs. Look out Python. ERM cleans up JS memory leaks, a must if your app needs to scale. Enzyme‚Äôs update aids testing rigor; Prism‚Äôs replay play needs validation with analytics suites. Upgrade stacks but verify integrations, and keep in mind efficiency should be a goal, but not an ends in itself. A subtle yet crucial difference CTOs learn through hard won experience.

Risk, Security & Compliance (RSC)
Context and Background
Over on the LC&S side it‚Äôs feeling more and more like what you get when too many AI commiters are given access to a repo with no merge policy. It‚Äôs a circus. Meta‚Äôs mounting an ‚Äúenshittification‚Äù defense against the FTC (‚Äúsince when is it illegal to suck?‚Äù), while Disney and NBCUniversal just filed the first major Hollywood lawsuit against a generative AI company (Midjourney) in LA federal court. Trump‚Äôs tech EOs are piling up: zero trust is out, post-quantum crypto stays, AI gets mandated across K‚Äì12 education. That last move helped fuel Miami-Dade‚Äôs rollout of Gemini bots to 105K high schoolers, just as New South Wales discovered Microsoft Teams was quietly harvesting students‚Äô voice and face biometric data with no prior consent. Privacy‚Äôs not for everyone, it seems (especially if you‚Äôre leaking secrets via Postman URLs.)

US Cybersecurity Policy Updates
President Trump‚Äôs Executive Orders EO#13694 ‚ÄúSustaining Select Efforts To Strengthen the Nation‚Äôs Cybersecurity and EO#14144 ‚ÄúAmending Executive and Executive Order‚Äù reverses ‚Äòmuch‚Äô of Biden‚Äôs cyber policy. They preserve efforts around post-quantum cryptography, advanced encryption standards, and border gateway protocol security, while hallmark programs tied to software bills of materials, zero-trust implementation, and space contractor cybersecurity requirements have been either rescinded or left in limbo

Technical Specs
FTC v. Facebook: Meta argues platform decay isn‚Äôt illegal; case drags into 2026.

Disney/NBC v. Midjourney: Lawsuit cites 10,000+ infringing images, seeks $150M.

Microsoft Teams: Collects voice/facial data since April 2025 with no opt-in.

Postman: Logs API secrets since v10.20, patched in v10.21.

Industry Impact
Postman‚Äôs slip-up demands immediate audits; CTOs, check your logs (but also, stop putting secrets in URLs, whether or not you are using Postman.) The Midjourney suit could redefine AI copyright; monitor outcomes. Trump‚Äôs policy flip keeps encryption but ditches zero-trust; time to assess your security stack. Miami‚Äôs chatbot push is bold, but NSW‚Äôs biometric snafu belies consent issues and Microsoft‚Äôs commitment. CTOs, tighten privacy controls; regulators *are* watching.

Web3 Whispers
Context and Background
In the high-stakes arena where regulatory clarity and technical innovation collide that is Web3, Amazon and Walmart both announced possible USD-backed stablecoins which would capture (or save, depending on your angle) billions of payment processing fees in global e-commerce transactions; a move made possible by the GENIUS Act (S.394). This bipartisan Senate bill (co-sponsored by NY Sen. Gillibrand) provides a federal framework for stablecoins, requiring 100 percent reserves, AML compliance, and consumer protections. (Tether could not be reached for comment.) Having cleared committee and cloture, it‚Äôs set for a final Senate vote on June 17. EMCD‚Äôs Spotlight Grant, launched June 11, offers $25,000 for L2/DeFi/GameFi auditable projects with sufficient market cap and live tokens ready to scale globally. It‚Äôs not just a cash grab; they‚Äôre aiming for long-term players, not pump-and-dump scams. But speaking of, Pump.fun‚Äôs raise/offering hints at a funding play; details are not surprisingly vague. Meanwhile, Proof of Talk‚Äôs Paris summit on June 10-11 brought 10,000+ Web3 folks to the Louvre, with a Bittensor track and startup pitch comp for VCs. Honestly it felt like less of a conference than a deal-making pit. Next, Nexa will be sponsoring the WAIB Summit in Monaco (June 27-28) showing off their new tech, a sign Middle East money‚Äôs flowing into Crypto. More on the tech side, Eclipse‚Äôs testnet now lets users pick fee lanes for speed or cost, and Quai Network‚Äôs merge-mined Layer 1 is pushing Proof-of-Entropy-Minima for real scalability. And Ethereum gas fees are stable at 20-30 gwei. But then, the price of ETH is stable at like 5 years ago. What cycle are we in again?

Technical Specs
Retail Stablecoins (Amazon/Walmart): Internal dev teams reportedly prototyping ERC-20 stablecoins for enterprise-grade compliance (whitelisted wallets, OFAC screening, programmable treasury logic) with estimated savings from legacy payments processors incl. Paypal/Stripe approaching $14B.

GENIUS Act (S.394): Provides legal clarity for fiat-backed stablecoins issued under U.S. jurisdiction with 1:1 reserves, bank custodian mandates, and Fed supervision for non-depository issuers; supports programmable compliance at the smart contract layer (e.g. blacklist/whitelist hooks, regulated attestations). Set for final Senate vote June 17.

EMCD Spotlight Grant: $25K marketing package, free listing for one winner; two runners-up get 50% off. Open to DeFi, GameFi, Layer 2 projects with live tokens. Deadline TBD.

Proof of Talk: June 10-11, Paris, 10,000+ attendees, Bittensor track, Proof of Pitch comp for startups.

Eclipse Testnet: Modular gas markets for user-selected fee lanes (speed vs. cost).

Quai Network: Merge-mined Layer 1 (100K+ TPS, sub-100ms finality) using proof-of-Entropy-Minima consensus is a bold scalability play, but N1‚Äôs horizontal scaling (also claiming 100K+ TPS, sub-1ms latency) and developer-friendly VMs (EVM, TypeScript-native SDK) may have something to say, especially with its 01 Exchange testnet going live in June. (Quai‚Äôs mainnet is post-January 2025, while N1‚Äôs is still pre-launch, so it‚Äôs a real race of execution.)

Pump.fun: Raise targets $50M, tied to NFT/decentralized app ecosystem; terms unclear. But then that only seems appropriate for pump.fun. I mean, who actually reads the tokenomics?

Industry Impact
Web3 isn‚Äôt sleeping, it‚Äôs consolidating. The GENIUS Act will force every serious stablecoin onto U.S.-compliant rails. Once (if?) Amazon/Walmart launch tokens, the game shifts from DeFi to embedded finance. Web3 CTOs building wallets, dApps, or any custody infra should prep for whitelisting logic, reserve attestations, and multi-stablecoin support now. EMCD‚Äôs Spotlight Grant is small cash, but big signal. It rewards projects with audits, traction, and tokens that aren‚Äôt a joke. If that‚Äôs you, apply. If it‚Äôs not, get there fast‚Äîgrants are replacing seed rounds for infra plays.

Eclipse‚Äôs modular gas lanes aren‚Äôt just a UX tweak, they‚Äôre a pricing primitive. Quai‚Äôs merge-mined PoEM is weird, but it works. If you‚Äôre still locked into a chain with 10x gas and 10s finality, you‚Äôre already behind. Run the benchmarks.

Proof of Talk and WAIB aren‚Äôt about keynotes. They‚Äôre where LPs and ecosystem funds pick who gets support next cycle. If you‚Äôre not sending someone who can cut a deal, you‚Äôre not in the room. Which raises the question, which Web3 companies have CTOs that can cut. deals?

One More Thing‚Ä¶
Starbucks‚Äô Green Dot Assist
Starbucks is rolling out ‚ÄúGreen Dot Assist,‚Äù a Microsoft Azure OpenAI assistant for baristas, promising order optimization; it integrates with POS systems and analyzes orders in <2s (which is ofc an eternity if you haven‚Äôt had your coffee.) It‚Äôs definitely AI spotted in the wild but ‚Äúless barista bot, more coffee whisperer.‚Äù Green Dot could streamline peak hours, but CTOs need to test reliability by placing extremely complicated coffee orders. Yes that‚Äôs a joke. No AI did not write this.

AI however *is* writing something no one else wants to. Code comments! Which apparently is the reason no one is commenting their code anymore (as if they ever did.) Comments in your code is now a sign (along with the infamous em-dash) that it was written by AI. Which raises the question though, why you don‚Äôt seen more em-dashes in code comments? ü§î

Until next month, see everyone at today‚Äôs lunch!

Forest Mars
CTO Lunches NYC

*To attend CTO Lunches, please register at ctolunches.com and choose NYC as your city.

11 Likes
‚àô
1 Restack

CTO Lunch August 2025
Tech Roundup for CTOs: July-August 2025 by Forest Mars
Aug 7 ‚Ä¢ Forest Mars

7

1



CTO Lunch NYC November 2025
Tech Roundup for CTOs: October ‚Üí November by Forest Mars
Nov 5 ‚Ä¢ CTO Lunch NYC and Forest Mars

7

1



Don't Lose Sleep Over It (Part 1)
CTOs literally lost sleep over the us-east-1 outage. Here's how to make sure you're not one of them next time.
Oct 28 ‚Ä¢ Forest Mars

5

1



CTO Lunch July 2025
Tech Roundup for CTOs: June‚ÄìJuly 2025
Jul 7 ‚Ä¢ Forest Mars

6




Turning Sand into Money
Why the Cost of Beached Assets Will Implode the 5:1 Capex-to-Revenue Ratio.
Dec 1 ‚Ä¢ Forest Mars

4





No Time To Spy
AI Espionage and What Anthropic Didn‚Äôt Say
Dec 4 ‚Ä¢ Forest Mars

4





CTO Lunch NYC September 2025
Tech Roundup for CTOs: August-September 2025
Sep 8 ‚Ä¢ Forest Mars and CTO Lunch NYC


1



CTO Lunch October 2025
Tech Roundup for CTOs: September-October by Forest Mars
Oct 8 ‚Ä¢ CTO Lunch NYC and Forest Mars





The Great (AI) Replacement
I saw the best devs of my generation destroyed by agents, prompting hysterical replaced
Dec 3 ‚Ä¢ CTO Lunch NYC and Forest Mars

2





The Engineering Guide to Control Plane Independence
Part 2 of Don't Lose Sleep Over It: Your Technical Remediation Playbook
Oct 31 ‚Ä¢ Forest Mars

2





¬© 2025 CTO Lunch NYC ¬∑ Privacy ‚àô Terms ‚àô Collection notice
Start your Substack
Get the app
Substack is the home for great culture

